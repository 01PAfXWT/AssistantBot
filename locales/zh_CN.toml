model = "模型"
bot = "机器人"
chat_bot = "聊天机器人"
completion_bot = "续写机器人"
baidu = "百度"
openai = "OpenAI"
openai_compatible = "OpenAI兼容"
qwen = "通义千问"
ollama = "Ollama"

add = "添加"
update = "更新"
delete = "删除"
save = "保存"
cancel = "取消"
confirm = "确认"
generate = "生成"
query = "查询"
querying = "查询"
backup = "备份"
restore = "恢复"
note = "注意"
test = "测试"

chat = "对话"
completion = "续写"
chats = "对话"
completions = "续写"
prompt = "提示词"
content = "内容"

paid = "付费"
free = "免费"

proxy = "代理"

enable = "启用"

load_archive = "导入存档"
prompt_management = "提示词管理"
settings = "设置"

reload_app = "重载应用"
open_archive_folder = "打开DATA"
open_backup_folder = "打开备份"

no_available_models_error = "未找到可用模型。请到`设置`页面添加模型，或启用LLM服务，或运行Ollama后刷新页面。"

ollama_model_disabled = "Ollama模型被禁用，请到 `Settings` 启用Ollama。"
ollama_server_not_running = "Ollama服务未运行，请检查Ollama是否运行。"
ollama_model_updated = "Ollama本地模型列表更新成功。"
query_ollama_model_failed = "查询Ollama模型失败。请检查ollama是否运行。发生错误: {e}。"

select_a_function = "选择一个功能"
configuration = "设置"
model_alias = '模型别名'
conversation_round = '对话轮数'
conversation_round_notice = "- 对话轮次：保留到下一轮对话的历史聊天消息数量。默认为6。\n - 对话轮次应根据所使用模型的上下文长度进行设置。\n - 用户输入的最终聊天消息在计算中计为一个对话轮次。"
backup_llms_configs = "备份LLM配置"
backup_llms_configs_success = "备份成功"

load_archive_label = "加载一个`{type}`存档继续`{work}`："

archive_management_caption = "可以查看项目存档文件夹内的`{chat}`或`{completion}`存档内容，对存档进行重命名与删除操作。"
no_archive_found = "{archive_folder}文件夹内没有找到存档。"

unable_load_configs = "无法加载config.toml配置文件。"
settings_caption = "配置通用设置、LLM服务供应商设置。"
common_settings = "通用设置"
language = "语言"
select_a_language = "选择要使用的语言"
language_switched_info = "语言已从 `{old_language}` 切换到 `{new_language}`。应用将重新加载以切换语言。"

web_port = "Web端口"
web_port_notice = "是否使用随机端口。默认是使用随机端口启动应用，以避免因端口被占用而导致无法启动或重新加载。如果是远程部署，建议使用固定端口，以便设置防火墙规则。默认端口号为Streamlit应用的默认端口8501，您可以自行修改端口号。"
random_web_port = "随机Web端口"
random_web_port_notice="Web端口设置已更改。应用程序将会以新的端口重新加载。如果应用程序在显示此消息后无法成功重新加载，则意味着分配的Web端口当前已被占用。请重新分配一个Web端口。"
set_web_port = "设置Web端口，默认是12345"
web_port_set_to = "Web端口设置为：{web_port}。"

data_folder_location = "DATA目录位置"
data_folder_description = "DATA文件夹默认位置为项目根目录下的`{default_data_folder}`文件夹。可以根据需要设置到其他文件夹。比如，设置到OneDrive等云盘文件夹可以同步数据。"
new_location = "新位置"
data_folder_set_to = "设置为：`{new_archive_folder}`"
data_folder_notice = "`{current_location}`内现存文件及子目录都会被移动到新位置 `{new_archive_folder}`。"
data_folder_clear_notice = "`{new_archive_folder}` 中的现有文件和子目录将被清除。"
data_folder_error = "`{new_archive_folder}` 不是一个有效的文件夹路径。"
data_folder_updated = "DATA目录位置已更新。"

refresh_interval = "页面刷新间隔时间"
refresh_interval_notice = "设置页面刷新间隔时间，单位为秒。"
refresh_interval_set_to = "刷新间隔时间设置为：{refresh_interval}秒。"
refresh_interval_updated = "刷新间隔时间已更新。"

proxy_setting_notice = "设置代理服务器。默认为本机代理http：`http://127.0.0.1:10809`, https：`http://127.0.0.1:10809`。"
http_proxy = "HTTP代理"
https_proxy = "HTTPS代理"
proxy_test_description = "通过连接Google.com测试代理是否可用。"
http_proxy_success = "HTTP代理 ({proxy}) 测试成功。"
https_proxy_success = "HTTPS代理 ({proxy}) 测试成功。"
http_proxy_failed = "Http代理 ({proxy}) 测试失败。"
https_proxy_failed = "Https代理 ({proxy}) 测试失败。"
proxy_not_set = "代理未设置。"

verbose_mode = "详细模式"
verbose_mode_description = "启用详细模式，在与LLM通信时在控制台中显示消息和参数值的信息。这对于故障排查特别有用。"
verbose_mode_label = "启用详细模式"
verbose_mode_updated = "详细模式设置已更新。"

llm_settings = "LLM设置"
activate_llm_provider = "LLM服务提供商"
llm_provider_activation_changed = "LLM服务提供商设置已更新"

conversation_round_updated = "对话轮数设置为：{conversation_round}。"

max_number_of_completions = "最大续写数量"
max_number_of_completions_description = "设置页面缓存续写的最大数量，默认为3。"
max_number_of_completions_updated = "最大续写数量设置为：{max_completions}。"

generating_content_notice = "根据`{prompt}`生成内容中..."
generating_content = "生成内容中..."
show_generated_content_title = "已生成 `{number}`个`{completion}`"
reach_max_completions_notice = "已达到最大续写数量。最早的记录将被覆盖。"
content_generated_notice = "@{time}：内容已生成。已复制到剪贴板。"

select_a_provider = "选择一个要设置的LLM服务提供商"
invalid_content_type = "内容类型错误，类型应该是chat或completion。"

clear_cache_button = "清除{content_type}缓存"
save_to_repository_button  = "保存到仓库"
download_history_button = "下载{content_type}记录"
clear_cached_history = "清除缓存的历史记录"
no_cached_history = "没有缓存的历史记录。"
content_saved = "{content_type_} 内容已保存。"
save_to_repository = "保存 `{file_name}` 到: `{repository_path}`."
download_history = "下载缓存的{content_type_}记录，默认文件名 {file_name}。"

proxy_status = "使用代理连接{provider}模型。代理设置：{proxies}。"

prompt_management_caption = "可以新增、修改、删除`{chat}`系统提示词或`{completion}`提示词。"
select_a_prompt_type = "选择一个提示词类型"
no_empty_prompt = "提示词不能为空。"
no_predefined_prompts = "没有预定义的提示词。"
selected_prompt = "选择的提示词"
new_prompt = "新提示词"
add_to_repository_label = "添加到{prompt_type}提示词仓库"
add_new_prompt_info = "新{prompt_type}提示词： {prompt}已添加，页面将会自动刷新。"

invalid_prompt_type = "无效的提示词类型。"
system_prompt = "系统提示词"
select_system_prompt_label = "选择一个预定义的系统提示词或者角色提示词。"
select_prompt_label = "选择一个提示词"

select_an_archive_type = "选择一个存档类型"

archive_management = "存档管理"
rename_archive = "重命名存档"
delete_archive = "删除存档"

open_folder = "打开存档文件夹"
file_to_be_renamed = "待重命名的文件：`{selected_archive_file}`。"
rename = "重命名"
new_file_name = "新文件名"
file_to_be_deleted = "待删除的文件：`{selected_archive_file}`。"

rename_archive_success = "`{old_name}` 已重命名 `{new_name}`，页面将会重新加载。"
rename_error_file_exists = "无法将 `{old_name}` 重命名为 `{new_name}`, 文件已存在。."
delete_archive_success = "`{selected_archive_file}` 删除成功，页面将会重新加载。如果是误操作，请到`回收站`手动恢复文件。"

selected_completion_archive = "选择了一个 `{completion}` 存档： `{file_name}`。该存档有 `{number}` 个 {completions}。"
show_prompt = "显示提示词"
generated_completion_info = "@{time}: `{model}` 根据 `{prompt}...` 生成的内容："
copy_completion = "复制续写{index}"
delete_completion = "删除续写{index}"
completion_content_copied = "内容已复制到剪贴板。"
content_deleted = "内容已删除。页面将会自动刷新。"
selected_chat_archive = "选择了一个 `{chat}` 存档： `{file_name}`。该存档有 `{number}` 个 {chats}。"

# LLM Provider Settings Block
provider_setting_block = "{provider} 模型设置"
add_new_model_description = "新增 `{provider}` 模型"
proxy_setting = "代理设置"
proxy_setting_label = "使用Proxy连接 `{provider}` 模型，根据上网环境自行设置，配合`通用设置`中的Proxy的设置使用："
# proxy_true = "使用代理"
# proxy_false = "不使用代理"
proxy_setting_updated = "代理设置已更新。"
provider_models = "{provider} 模型"
provider_supported_models = "`{provider}` 支持的模型："
last_query_time = "最后查询时间: {time}"
query_provider_models = "点击`查询`按钮查询或更新 `{provider}` 支持的模型。"

provider_api_key_title = "{provider} API Key"
provider_api_key_description = "API Key 是 `{provider}` 平台的认证信息。"
provider_api_key_label = "{provider} API Key"
no_provider_api_key_found = "没有找到 `{provider}` API Key，请先添加一个API Key。"
api_key_cannot_be_empty = "API Key 不能为空。"
api_key_updated = "{provider} API Key 已更新。"

provider_model_not_found = "没有找到已添加的 `{provider}` 模型。"
provider_model_management = "管理已保存的 `{provider}` 模型"
provider_select_a_model = "选择一个模型，查询或修改模型信息。"

baidu_auth_info = "Client ID 和 Client Secret 是百度AI平台的认证信息。Client ID也就是AK，Client Secret也就是SK。"
baidu_client_id = "百度Client ID, aka, AK"
baidu_client_secret = "百度Client Secret, aka, SK"
baidu_auth_info_updated = "百度认证信息已更新。"

qianfan_supported_models = "百度千帆 SDK(`{version}`)支持的模型"
qianfan_update_notice = "注意：千帆SDK支持的模型列表可能会有更新，建议使用`pip install qianfan --upgrade`更新qianfan，以支持最新的模型列表。"
paid_model_list = "收费模型列表"
free_model_list = "免费模型列表"
support_pass_system_prompt_by_parameter = "支持以system参数传入system prompt的模型"
not_support_pass_system_prompt_by_parameter = "不支持以system参数传入system prompt的模型，将自动把system prompt添加到第一条message的开始"
baidu_model_name_description = "Baidu预置模型名称。可以在`https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Jlugqd6pw`查询，或查询上面的`千帆SDK(v.{qianfan.version.VERSION})支持的模型列表`。"
qwen_model_name_description = "通义千问支持的模型列表`https://bailian.console.aliyun.com/#/model-market`查询。"
# model management block
model_management_description = "- `模型别名` 是对模型的自定义名称，方便识别，比如`OpenAI-GPT4-o`，`百度文心4-turbo`，`通义千问MAX`。\n - `模型名称` 是模型在 `{provider}` 平台的唯一标识，必须是平台所预置的模型名称，比如`gpt4-o`，`ERNIE-4.0-Turbo-8K`，`qwen-max`等等。"
model_alias_label = "模型别名"
model_name_label = "模型名称"
model_description_label = "模型描述"
model_description_with_colon = "模型描述："
no_model_description = "没有找到模型描述。"
model_architecture_description_label = "模型架构："
chat_support = "支持对话"
completion_support = "支持续写"
model_payment_type = "付费类型"

using_proxy_to_connect = "使用代理连接"
using_proxy_to_connect_to = "使用代理连接 `{provider}`"

add_new_model = "新增 `{provider}` 的 `{modified_model_alias}` 模型。"
update_model = "`{provider}` 的 `{model_alias}` 模型已更新。"
openai_supported_models_updated = "OpenAI支持的模型已更新。"

change_model_alias = "`{provider}` 的 `{model_alias}` 模型别名已更改为 `{modified_model_alias}`。"

openai_compatible_api_key = "OpenAI兼容API Key"
openai_compatible_base_url = "OpenAI兼容Base URL，以`v1`结尾，如：OpenAI官方的`https://openai.api2d.net/v1`， Ollama的为`http://localhost:11434/v1`。"

delete_model_success = "`{provider}` 的 `{model_alias}` 模型已删除，页面将会重新加载。"
delete_model_failed = "`{provider}` 的 `{model_alias}` 模型删除失败。"

ollama_server = "Ollama服务"
ollama_server_running = "正在运行"
ollama_server_stopped = "已停止"
ollama_server_status = "Ollama服务状态"
ollama_models_list = "Ollama模型列表"
select_a_model = "选择一个模型"
ollama_model_brief_introduction = "点击查看 {selected_model} 模型简要信息"
ollama_model_detailed_introduction = "点击查看 {selected_model} 模型详细信息"
ollama_model_alias_settings = "Ollama模型别名设置"
add_prefix_to_ollama_model_label = "为Ollama模型添加前缀作为模型别名"
ollama_model_alias_setting_option_1 = "使用 `前缀-模型` 作为模型别名"
ollama_model_alias_setting_option_2 = "使用 `模型` 作为模型别名"
ollama_model_alias_prefix_label = "模型别名前缀，默认是 `Ollama-`"
ollama_model_alias_prefix_option_updated = "Ollama模型别名前缀设置已更新。页面将重新加载。"
ollama_model_alias_example = "例: `{prefix}{model}`"
ollama_exclude_models_setting_title = "Ollama排除模型"
add_prefix_to_ollama_model_updated = "Ollama模型别名前缀设置已更新。页面将重新加载。"
ollama_exclude_models_setting_description = "设置要排除的Chat / Completion模型的别名，这些模型将被排除在本地Chat / Completion模型列表之外。通常是ollama的embedding model，如`nomic-embed-text`。"
ollama_exclude_models_label = "要排除的模型别名，只需要填写模型别名或别名中的模型名称即可，多个模型用 `,` 分隔："
ollama_exclude_models_changed = "Ollama排除的模型已更新。页面将很快重新加载以应用更改。"
ollama_exclude_models_no_changed = "Ollama排除模型设置未更改。"

backup_and_restore = "备份和还原"
backup_info = "备份通用设置、LLM模型设置（包括提示词）和所有{chat}/{completion}存档。\n - 备份文件保存在 `data` 目录下的 `backups` 文件夹中。\n - 备份文件名为 `{backup_file_name}`，例如 `{current_file_name}`。"
restore_info = "选择一个备份文件进行还原。\n - 还原操作将覆盖当前的配置文件、模型设置和{chat}/{completion}存档。\n - 还原操作将重新加载应用程序以恢复备份配置。"
backup_error = "备份失败。"
restore_error = "还原失败。发生错误：{error}。"
backup_success = "备份成功。备份文件保存为：{backup_file_fullpath}。"
restore_success = "还原成功。应用程序将重新加载以应用还原配置。"
select_backup_file = "选择一个备份文件"
delete_backup_success = "备份文件 `{backup_file}` 删除成功。如果是误操作，请到`回收站`手动恢复文件。"
delete_backup_failed = "备份文件 `{backup_file}` 删除失败。"
no_backup_files = "没有找到备份文件。"
request_parameters_additional_info = "以下是支持的请求参数，默认值由模型提供者提供。有关详细信息，请参阅模型提供者的官方文档。"
no_available_provider = "没有可用的LLM服务提供商。请先启用一个LLM服务提供商。"
# model parameter block
set_model_parameters = "设置 `{model_alias}`/ `{model}`模型参数："
seed_description = "设置随机种子用于复现，默认为1234。"
temperature_description = "设置温度值，用于控制生成文本的创造性，更大更随机。"
top_p_description = "设置Top-p值，用于控制生成文本的多样性，更大更多样。"
presence_penalty_description = "设置Presence Penalty值，提高取值用于提升生成文本的多样性。默认为 `0`"
frequency_penalty_description = "设置Frequency Penalty值，提高取值用于降低模型生成的重复度。默认为 `0`。"
repetition_penalty_description = "设置Repetition Penalty值，提高取值用于降低模型生成的重复度。默认为 `1.0`，不惩罚重复。"
repeat_penalty_description = "设置重复惩罚以控制文本生成质量，值越高越严格。默认为 `1.1`。"
max_tokens_description = "设置最大生成文本长度。"
max_tokens_additional_info = "`{openai}` 和 `{qwen}` 模型的最大token数由模型决定。"
max_output_tokens_description = "设置最大生成文本长度。"
penalty_score_description = "设置惩罚分数，用于控制生成文本的质量，更大更严格。"
num_ctx_description = "设置上下文数量，用于控制生成文本的质量，根据Ollama模型自动设置。"
top_k_description = "设置Top-k值，用于减少生成无意义内容的概率。"
repeat_penalty_block = "重复惩罚"
num_predict_description = "设置预测数量，用于控制生成文本的质量，根据Ollama模型设置，-1表示无限制，-2表示填充上下文。"
provider_models_only = "`{provider}`模型专用。"
disable_search_description = "禁用搜索，默认是启用搜索。"
enable_search_description = "启用搜索，默认是禁用搜索。"
provider_default_value = "`{provider}` 模型默认为 `{default}`"
request_parameters_description = "请求参数"
request_parameters_info = "请求参数是用于控制模型生成文本的质量和多样性的参数。"
request_parameters_notice = "所有请求参数都是可选的，即使不添加请求参数，大模型也能正确生成内容。但通过使用请求参数，可以控制生成内容的多样性。如果使用固定的请求参数，你甚至可能复现大模型生成的内容。"
request_parameters_format = "参考`{llm_settings}`内的参数说明输入请求参数，多个参数使用`,`隔开。留空的话将不设置请求参数。"
unsupported_request_parameter = "不支持的请求参数`{parameter}`，请删除后重试。"
no_request_parameters_found = "没有设定 `{model_alias}` 的请求参数。"
recommended_request_parameters_title = "官方API文档常用的请求参数"
recommended_request_parameters_description= "以下是各官方API文档提供的常用请求参数。请注意，即使是同一个服务提供商，不同的模型可能支持的请求参数也不同。"
recommended_request_parameters_by_provider = "**{provider}**: `{parameters}` 。"
official_api_document = "{provider}官方文档: {url} 。"
openai_compatible_request_parameters_description = "可能 `支持` 也可能 `不支持` 请求参数。详情请参见所添加模型的官方文档。"
ollama_request_parameters_updated = "Ollama模型请求参数已更新。"
updating_ollama_request_parameters = "正在更新Ollama模型请求参数..."
ollama_model_request_parameters_updated = "Ollama模型 `{model_alias}` 请求参数已更新。"
ollama_request_parameters_not_set = "Ollama模型请求参数未设置。"

# request parameters
customize_request_parameters = "自定义请求参数"
customize_request_parameters_description = "您可以在此添加、修改、删除请求参数。添加后即可在模型设置中使用。当前支持添加 `{param_types}` 类型的请求参数。添加自定义参数需**注意：**\n - 请求参数名称不能和预定义参数重复。\n - 请求参数名称必须是模型支持的。\n - 禁止添加`stop`的字符串以免造成不能正确接受模型返回信息。"
no_customized_request_parameters = "未找到自定义请求参数。请先添加一个新的请求参数。"
request_parameter_name = "请求参数名称"
request_parameter_name_empty = "请求参数名称不能为空。"
request_parameter_name_duplicated = "请求参数名称 `{parameter}` 重复。"
request_parameter_type = "请求参数类型"
request_parameter_default_value = "默认值"
request_parameter_min_value = "最小值"
request_parameter_max_value = "最大值"
request_parameter_adjust_step = "调整步长"
request_parameter_description = "请求参数描述"
request_parameter_description_notice = "请求参数的描述将添加到所有现有的语言文件中。"
add_request_parameter = "添加请求参数"
add_request_parameter_success = "请求参数 `{parameter}` 添加成功。"
add_request_parameter_description = "请求参数 `{parameter}` 的描述已添加到语言文件 `{files}` 中。"
add_variable_to_language_files_error = "未能将请求参数 `{parameter}` 添加到语言文件中。"
select_a_request_parameter = "选择一个请求参数"
update_request_parameter = "更新请求参数"
update_request_parameter_success = "请求参数 `{parameter}` 更新成功。"
delete_request_parameter = "删除请求参数"
request_parameter_name_to_delete = "请求参数 `{parameter}` 将被删除。"
delete_request_parameter_success = "请求参数 `{parameter}` 删除成功。页面将很快重新加载。"
delete_request_parameter_description = "请求参数 `{parameter}` 已从语言文件 `{files}` 中删除。"
request_parameter_not_found_in_language_files = "在语言文件中未找到请求参数 `{parameter}`。"
default_value_out_of_range = "默认值超出范围，应在 `{min_value}` 和 `{max_value}` 之间。"
min_value_greater_than_max_value = "最小值应小于最大值。"
empty_variable_value = "{variable} 的值不能为空。"
querying_models = "查询 `{provider}` 模型..."
archive_file_naming_rule = "存档文件命名规则"
archive_file_naming_rule_description = "存档文件（*.json）的命名规则目前仅支持三个预定义变量：`{{timestamp}}`、`{{type}}` 和 `{{model}}`。\n- `{{timestamp}}` 表示当前时间，例如 {timestamp}。\n - `{{type}}` 是 `chat`或`completion`。\n - `{{model}}` 是模型名称。\n\n默认的命名格式为 `[{{timestamp}}]-[{{type}}]-[{{model}}]`。例如，`{example}`。"
archive_file_naming_rule_updated = "存档文件命名规则已更新。"
archive_file_naming_rule_invalid = "无效的存档文件命名规则。目前仅支持三个预定义变量：`{timestamp}`、`{type}` 和 `{model}`。"
add_common_request_parameters_to_new_model = "新模型添加常用请求参数"
add_common_request_parameters_when_adding_model_label = "在添加模型时添加常用请求参数。"
add_common_request_parameters_when_adding_model_description = "在添加新模型时将常用请求参数添加到模型中。常用请求参数如 {section} 中所示。"
add_common_request_parameters_to_new_model_option_updated = "添加常用请求参数到新模型的选项已更新。"
# customized request parameters
customized_request_param_new_boolean_param_description = "customized boolean parameter."
customized_request_param_new_float_param_description = "customized float parameter."



